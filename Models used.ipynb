{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e3fa4d7-ccda-4a98-8503-c19f072b74c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santh\\AppData\\Local\\Temp\\ipykernel_10272\\3462630793.py:30: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels = np.array(pd.factorize(labels)[0])  # Convert labels to integers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Dataset parameters\n",
    "dataset_path = 'D:/Projects/AIML/Image-detection-AI-MODEL-main/Image-detection-AI-MODEL-main/Dataset'  # Replace with your dataset path\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data loading and preprocessing\n",
    "def load_data(dataset_path, img_size=IMG_SIZE):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label_dir in os.listdir(dataset_path):\n",
    "        label_path = os.path.join(dataset_path, label_dir)\n",
    "        if os.path.isdir(label_path):\n",
    "            for img_file in os.listdir(label_path):\n",
    "                img_path = os.path.join(label_path, img_file)\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (img_size, img_size))  # Resize image\n",
    "                images.append(img)\n",
    "                labels.append(label_dir)\n",
    "    \n",
    "    images = np.array(images) / 255.0  # Normalize images\n",
    "    labels = np.array(pd.factorize(labels)[0])  # Convert labels to integers\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_data(dataset_path)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51627772-7597-4f69-8e86-449b7bd82041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santh\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santh\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 298ms/step - accuracy: 0.0429 - loss: 3.1826 - val_accuracy: 0.0496 - val_loss: 3.1333\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 0.0381 - loss: 3.1330 - val_accuracy: 0.0780 - val_loss: 3.1312\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 186ms/step - accuracy: 0.0500 - loss: 3.1369 - val_accuracy: 0.0780 - val_loss: 3.1327\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.0826 - loss: 3.1244 - val_accuracy: 0.0780 - val_loss: 3.1276\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 222ms/step - accuracy: 0.0496 - loss: 3.1173 - val_accuracy: 0.0780 - val_loss: 3.1309\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 0.0594 - loss: 3.1301 - val_accuracy: 0.0780 - val_loss: 3.1286\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.0455 - loss: 3.1243 - val_accuracy: 0.0780 - val_loss: 3.1287\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.0570 - loss: 3.1314 - val_accuracy: 0.0709 - val_loss: 3.1242\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - accuracy: 0.0464 - loss: 3.1344 - val_accuracy: 0.0355 - val_loss: 3.1265\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.0841 - loss: 3.1253 - val_accuracy: 0.0780 - val_loss: 3.1212\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.0557 - loss: 3.1180 - val_accuracy: 0.0851 - val_loss: 3.1165\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.0527 - loss: 3.1201 - val_accuracy: 0.0709 - val_loss: 3.1131\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.0538 - loss: 3.1208 - val_accuracy: 0.0567 - val_loss: 3.1204\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.0906 - loss: 3.1022 - val_accuracy: 0.0638 - val_loss: 3.1120\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.0632 - loss: 3.1104 - val_accuracy: 0.0780 - val_loss: 3.1125\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.0686 - loss: 3.1022 - val_accuracy: 0.0355 - val_loss: 3.1220\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - accuracy: 0.0695 - loss: 3.0933 - val_accuracy: 0.0922 - val_loss: 3.1365\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 152ms/step - accuracy: 0.1038 - loss: 3.0712 - val_accuracy: 0.1064 - val_loss: 3.1235\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.0787 - loss: 3.0785 - val_accuracy: 0.0496 - val_loss: 3.1294\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - accuracy: 0.0941 - loss: 3.0918 - val_accuracy: 0.0355 - val_loss: 3.1740\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.29      0.20      0.24        10\n",
      "           2       0.00      0.00      0.00        11\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.00      0.00      0.00         8\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.03      0.75      0.06         4\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.00      0.00      0.00         6\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.00      0.00      0.00         4\n",
      "          20       0.00      0.00      0.00         6\n",
      "          21       0.00      0.00      0.00         5\n",
      "          22       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.04       141\n",
      "   macro avg       0.01      0.04      0.01       141\n",
      "weighted avg       0.02      0.04      0.02       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_cnn():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(np.unique(labels)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train CNN model\n",
    "cnn_model = build_cnn()\n",
    "cnn_model.fit(train_generator, epochs=20, validation_data=(X_test, y_test))\n",
    "y_pred_cnn = np.argmax(cnn_model.predict(X_test), axis=1)\n",
    "print(classification_report(y_test, y_pred_cnn))\n",
    "cnn_model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d27af7d-b921-4a04-a8db-c7503c49ec27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.0423 - loss: 3.4804 - val_accuracy: 0.0709 - val_loss: 3.1059\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 992ms/step - accuracy: 0.0717 - loss: 3.0520 - val_accuracy: 0.0993 - val_loss: 3.0582\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 938ms/step - accuracy: 0.1330 - loss: 2.9945 - val_accuracy: 0.0709 - val_loss: 3.0267\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.1142 - loss: 2.9246 - val_accuracy: 0.1064 - val_loss: 3.0022\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - accuracy: 0.1482 - loss: 2.8503 - val_accuracy: 0.1560 - val_loss: 2.9353\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.1726 - loss: 2.7964 - val_accuracy: 0.1277 - val_loss: 2.9834\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.1768 - loss: 2.6819 - val_accuracy: 0.1560 - val_loss: 2.9281\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.2108 - loss: 2.6805 - val_accuracy: 0.1631 - val_loss: 2.8971\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.2464 - loss: 2.5351 - val_accuracy: 0.1844 - val_loss: 2.8979\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.2644 - loss: 2.5122 - val_accuracy: 0.1631 - val_loss: 2.8838\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.2988 - loss: 2.4165 - val_accuracy: 0.1418 - val_loss: 2.9126\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.3023 - loss: 2.3734 - val_accuracy: 0.1844 - val_loss: 2.8632\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.2938 - loss: 2.3511 - val_accuracy: 0.1560 - val_loss: 2.8609\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.3243 - loss: 2.2869 - val_accuracy: 0.1702 - val_loss: 2.8478\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.3124 - loss: 2.2511 - val_accuracy: 0.1631 - val_loss: 2.8170\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.3528 - loss: 2.2169 - val_accuracy: 0.1348 - val_loss: 2.8701\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.3487 - loss: 2.0914 - val_accuracy: 0.1844 - val_loss: 2.8576\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.3472 - loss: 2.0897 - val_accuracy: 0.1418 - val_loss: 2.8620\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.4208 - loss: 2.0068 - val_accuracy: 0.1489 - val_loss: 2.8464\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.4390 - loss: 1.8599 - val_accuracy: 0.1986 - val_loss: 2.8011\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 849ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.50      0.36         4\n",
      "           1       0.12      0.20      0.15        10\n",
      "           2       0.40      0.18      0.25        11\n",
      "           3       0.18      0.33      0.24         6\n",
      "           4       0.29      0.18      0.22        11\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.29      0.29      0.29         7\n",
      "           7       0.50      0.17      0.25         6\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.11      0.12      0.12         8\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.43      0.67      0.52         9\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.07      0.25      0.11         4\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.40      0.29      0.33         7\n",
      "          17       0.00      0.00      0.00         6\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.17      0.25      0.20         4\n",
      "          20       0.00      0.00      0.00         6\n",
      "          21       0.25      0.20      0.22         5\n",
      "          22       0.33      0.75      0.46         4\n",
      "\n",
      "    accuracy                           0.20       141\n",
      "   macro avg       0.17      0.19      0.16       141\n",
      "weighted avg       0.19      0.20      0.18       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "def build_vgg16():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(np.unique(labels)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train VGG16 model\n",
    "vgg16_model = build_vgg16()\n",
    "vgg16_model.fit(train_generator, epochs=20, validation_data=(X_test, y_test))\n",
    "y_pred_vgg16 = np.argmax(vgg16_model.predict(X_test), axis=1)\n",
    "print(classification_report(y_test, y_pred_vgg16))\n",
    "vgg16_model.save('vgg16_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec71e85-6ca7-45d4-87c3-748eff03b9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.0369 - loss: 3.3183 - val_accuracy: 0.0496 - val_loss: 3.1258\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 810ms/step - accuracy: 0.0509 - loss: 3.1516 - val_accuracy: 0.0355 - val_loss: 3.1163\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 719ms/step - accuracy: 0.0564 - loss: 3.1371 - val_accuracy: 0.0496 - val_loss: 3.1216\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 712ms/step - accuracy: 0.0717 - loss: 3.1445 - val_accuracy: 0.0355 - val_loss: 3.1258\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 791ms/step - accuracy: 0.0597 - loss: 3.1215 - val_accuracy: 0.0355 - val_loss: 3.1115\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 837ms/step - accuracy: 0.0458 - loss: 3.1342 - val_accuracy: 0.0993 - val_loss: 3.1256\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 615ms/step - accuracy: 0.0590 - loss: 3.1279 - val_accuracy: 0.0284 - val_loss: 3.1209\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 713ms/step - accuracy: 0.0788 - loss: 3.1067 - val_accuracy: 0.0567 - val_loss: 3.1151\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 738ms/step - accuracy: 0.0471 - loss: 3.1209 - val_accuracy: 0.0851 - val_loss: 3.1073\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 582ms/step - accuracy: 0.0598 - loss: 3.1229 - val_accuracy: 0.0709 - val_loss: 3.1034\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 584ms/step - accuracy: 0.0637 - loss: 3.1082 - val_accuracy: 0.0638 - val_loss: 3.1148\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 581ms/step - accuracy: 0.0675 - loss: 3.1095 - val_accuracy: 0.0496 - val_loss: 3.1191\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 665ms/step - accuracy: 0.0579 - loss: 3.1141 - val_accuracy: 0.0638 - val_loss: 3.1187\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 672ms/step - accuracy: 0.0654 - loss: 3.1061 - val_accuracy: 0.0355 - val_loss: 3.1169\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 603ms/step - accuracy: 0.0603 - loss: 3.1194 - val_accuracy: 0.0284 - val_loss: 3.1130\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 569ms/step - accuracy: 0.0536 - loss: 3.1001 - val_accuracy: 0.0426 - val_loss: 3.1106\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 531ms/step - accuracy: 0.0809 - loss: 3.1071 - val_accuracy: 0.0426 - val_loss: 3.1151\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 507ms/step - accuracy: 0.0446 - loss: 3.1138 - val_accuracy: 0.0638 - val_loss: 3.1152\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 507ms/step - accuracy: 0.0555 - loss: 3.1102 - val_accuracy: 0.0496 - val_loss: 3.1104\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 605ms/step - accuracy: 0.0711 - loss: 3.1066 - val_accuracy: 0.0780 - val_loss: 3.1190\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001EDD8EB20C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001EDD8EB20C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 397ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001EDD8EB20C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001EDD8EB20C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.00      0.00      0.00        11\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.09      1.00      0.16        11\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.00      0.00      0.00         8\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.00      0.00      0.00         4\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.00      0.00      0.00         6\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.00      0.00      0.00         4\n",
      "          20       0.00      0.00      0.00         6\n",
      "          21       0.00      0.00      0.00         5\n",
      "          22       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.08       141\n",
      "   macro avg       0.00      0.04      0.01       141\n",
      "weighted avg       0.01      0.08      0.01       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "def build_resnet50():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(np.unique(labels)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train ResNet50 model\n",
    "resnet50_model = build_resnet50()\n",
    "resnet50_model.fit(train_generator, epochs=20, validation_data=(X_test, y_test))\n",
    "y_pred_resnet50 = np.argmax(resnet50_model.predict(X_test), axis=1)\n",
    "print(classification_report(y_test, y_pred_resnet50))\n",
    "resnet50_model.save('resnet50_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcac792e-8c9e-4c5c-85ed-b2b3b70d9a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santh\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.0554 - loss: 7.7077 - val_accuracy: 0.0709 - val_loss: 3.1542\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.0398 - loss: 3.1346 - val_accuracy: 0.0780 - val_loss: 3.1340\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.0499 - loss: 3.1353 - val_accuracy: 0.0780 - val_loss: 3.1334\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.0827 - loss: 3.1335 - val_accuracy: 0.0780 - val_loss: 3.1329\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.0664 - loss: 3.1337 - val_accuracy: 0.0780 - val_loss: 3.1324\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.0582 - loss: 3.1333 - val_accuracy: 0.0780 - val_loss: 3.1321\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 0.0658 - loss: 3.1324 - val_accuracy: 0.0780 - val_loss: 3.1315\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3s/step - accuracy: 0.0760 - loss: 3.1308 - val_accuracy: 0.0780 - val_loss: 3.1311\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.0585 - loss: 3.1317 - val_accuracy: 0.0780 - val_loss: 3.1306\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.0664 - loss: 3.1299 - val_accuracy: 0.0780 - val_loss: 3.1302\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.0642 - loss: 3.1302 - val_accuracy: 0.0780 - val_loss: 3.1298\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.0694 - loss: 3.1282 - val_accuracy: 0.0780 - val_loss: 3.1293\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.0750 - loss: 3.1287 - val_accuracy: 0.0780 - val_loss: 3.1288\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.0670 - loss: 3.1296 - val_accuracy: 0.0780 - val_loss: 3.1285\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.0573 - loss: 3.1283 - val_accuracy: 0.0780 - val_loss: 3.1282\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3s/step - accuracy: 0.0635 - loss: 3.1282 - val_accuracy: 0.0780 - val_loss: 3.1279\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.0608 - loss: 3.1276 - val_accuracy: 0.0780 - val_loss: 3.1274\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.0441 - loss: 3.1298 - val_accuracy: 0.0780 - val_loss: 3.1272\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.0580 - loss: 3.1281 - val_accuracy: 0.0780 - val_loss: 3.1268\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.0729 - loss: 3.1249 - val_accuracy: 0.0780 - val_loss: 3.1264\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 456ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.00      0.00      0.00        11\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.08      1.00      0.14        11\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.00      0.00      0.00         8\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.00      0.00      0.00         4\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.00      0.00      0.00         6\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.00      0.00      0.00         4\n",
      "          20       0.00      0.00      0.00         6\n",
      "          21       0.00      0.00      0.00         5\n",
      "          22       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.08       141\n",
      "   macro avg       0.00      0.04      0.01       141\n",
      "weighted avg       0.01      0.08      0.01       141\n",
      "\n",
      "Accuracy Score: 0.07801418439716312\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "\n",
    "# Preparing the data for ConvLSTM\n",
    "# ConvLSTM expects a 5D tensor: (samples, timesteps, rows, cols, channels)\n",
    "# Here, we simulate \"timesteps\" by adding a dummy dimension\n",
    "\n",
    "def prepare_data_for_convlstm(images, timesteps=1):\n",
    "    # Adding a time dimension for ConvLSTM (assuming static images treated as one timestep each)\n",
    "    images = np.expand_dims(images, axis=1)  # Shape: (samples, timesteps, rows, cols, channels)\n",
    "    return images\n",
    "\n",
    "X_train_lstm = prepare_data_for_convlstm(X_train)\n",
    "X_test_lstm = prepare_data_for_convlstm(X_test)\n",
    "\n",
    "# Model Definition\n",
    "def build_convlstm(input_shape):\n",
    "    model = Sequential([\n",
    "        # ConvLSTM layer\n",
    "        ConvLSTM2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=input_shape, return_sequences=False),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # Fully connected layers\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(np.unique(labels)), activation='softmax')  # Output layer with softmax\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "input_shape = (X_train_lstm.shape[1], IMG_SIZE, IMG_SIZE, 3)  # (timesteps, rows, cols, channels)\n",
    "convlstm_model = build_convlstm(input_shape)\n",
    "\n",
    "# Train the model\n",
    "history = convlstm_model.fit(\n",
    "    X_train_lstm, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test_lstm, y_test)\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_lstm = np.argmax(convlstm_model.predict(X_test_lstm), axis=1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lstm))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_lstm))\n",
    "\n",
    "# Save the model\n",
    "convlstm_model.save('convlstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f715b804-0230-4659-937c-76c0922f4759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is VGG16.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\santh\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Summarizing model performance\n",
    "model_reports = {\n",
    "    \"CNN\": classification_report(y_test, y_pred_cnn, output_dict=True),\n",
    "    \"VGG16\": classification_report(y_test, y_pred_vgg16, output_dict=True),\n",
    "    \"ResNet50\": classification_report(y_test, y_pred_resnet50, output_dict=True),\n",
    "    \"ConvLSTM\": classification_report(y_test, y_pred_lstm, output_dict=True),\n",
    "}\n",
    "\n",
    "best_model_name = max(model_reports, key=lambda x: model_reports[x]['accuracy'])\n",
    "print(f\"The best model is {best_model_name}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
